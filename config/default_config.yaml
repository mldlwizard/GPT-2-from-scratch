model:
  block_size: 1024
  vocab_size: 50257
  n_layer: 12
  n_head: 12
  n_embd: 768

training:
  num_epochs: 50
  batch_size: 4
  sequence_length: 32
  learning_rate: 3e-4
  device: 'cuda'

data:
  input_file: 'input.txt'

logging:
  log_interval: 10
  save_interval: 1000
  model_save_path: 'checkpoints/'